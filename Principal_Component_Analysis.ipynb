{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Principal Component Analysis",
      "provenance": [],
      "authorship_tag": "ABX9TyN97QDT+V1W4nl5bbj59Zab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinLolochum/Top-Ten-Machine-Learning-Cheatsheet/blob/main/Principal_Component_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UDFVN7rzaPY"
      },
      "source": [
        "## 9. Principal Component Analysis\n",
        "For dimensionality reduction\n",
        "\n",
        "> Layman:\n",
        "\n",
        "PCA can be used for several purposes in machine learning. One of these uses is called dimensionality reduction. Dimensionality reduction of data is like when a company downsizes. The company hopes to improve its profitability by reducing overhead costs and mantaining or even improving it's revenue.\n",
        "\n",
        "> Hiring manager:\n",
        "\n",
        "Principal component analysis is an algorithm that is used to find similar variations between variables. For dimensionality reduction PCA helps to reduce cardinality of data without affecting the outcome of predictions by ignoring duplicate variations(noise).\n",
        "\n",
        "> Programmer:\n",
        "\n",
        "* You have many variables Xi,1...Xi,t. Where i is the number of examples (samples).\n",
        "* Create another variable Z with ***i*** samples, by weighing the X variables e.g Z1 = W1,1*X1+...+W1,t*Xt.\n",
        "* Z1, Z2..ZI should be weighted such that there is no correlation between them.\n",
        "* Select K components (**K < i**) that maximizes explained variance between the X variables (X1..Xt).\n",
        "* The weights from K are then taken and used for to create new values of X variables for the i examples.\n",
        "* Here is the [SKlearn code](https://github.com/KevinLolochum/Top-Ten-Machine-Learning-Cheatsheet/blob/main/PCA.py)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}