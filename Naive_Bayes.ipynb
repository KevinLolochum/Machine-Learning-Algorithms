{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes",
      "provenance": [],
      "authorship_tag": "ABX9TyMs3IjskUgqctEePYWGbr9S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinLolochum/Top-Ten-Machine-Learning/blob/main/Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exylvp7TGoO4"
      },
      "source": [
        "## 3. Naive Bayes\n",
        "\n",
        "> Layman:\n",
        "\n",
        "Imagine that you work for ‘fakenews.com’ and you are trying to use age, education and income to determine whether someone is a Johnie, Al, or Tom supporter. Naïve Bayes can help you answer this question but it assumes that age, education and income are independent(do not affect) of each other. This might not be true sometimes, for example a high level education might lead to a higher income. In some cases the assumption made can hold.\n",
        "\n",
        "> Hiring manager:\n",
        "\n",
        "Naïve Bayes is a supervised learning classification method that takes inputs and returns two or more classes as outputs. Importantly, Naïve Bayes assumes that the inputs are independent of each other when calculating the probability of belonging to a certain class. There are three types of Naïve Bayes. GNB takes continuous inputs that are assumed to have a normal distribution, MNB takes whole integer inputs while BNB takes inputs that are binary. \n",
        "\n",
        "> Programmer:\n",
        "* Assuming that predictor variables Xi..Xj are independent calculate the conditional propability of Xi--Xj given a prediction Y=k e.g P(Xi|Y=k)\n",
        "* Multiply the probabilities of variables by each other and by propotion of values in Y=k (sum(Y=k)/lenY).\n",
        "* Repeat above step for all classes, Y=1...Y=k.\n",
        "* Estimate propability of a class Y=k by taking the value in step 2 and dividing by sum of values in step 3. The class with the highest probability is the class of that record/sample.\n",
        "* [Code](https://github.com/KevinLolochum/Top-Ten-Machine-Learning/blob/main/Naive%20Bayes.py).\n"
      ]
    }
  ]
}