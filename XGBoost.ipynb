{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost",
      "provenance": [],
      "authorship_tag": "ABX9TyNDwh/wYvi8u2hXtFh/Ou5N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinLolochum/Top-Ten-Machine-Learning-Cheatsheet/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UsLrs6TUAC1"
      },
      "source": [
        "## 7. XGBoost\n",
        "\n",
        "\n",
        "> Layman:\n",
        "\n",
        "When a phone company makes a new phone, we believe that it is an improvement of the previous model. The people who make this happen must look at the previous versions to determine how they can improve them. Sometimes, they improve some features of the phone and deteriorate others. This is what gradient boosting does to data prediction. XGBoost takes this boosting to the limits and is also faster and more efficient than gradient boosting.\n",
        "\n",
        "> Hiring manager:\n",
        " \n",
        "XGBoost is type of boosting ensemble algorithm that takes several base estimators and fits them into the data sequentially so that each learner is an improvement of the previous learner. XGBoost uses sgd boosting algorithm optimized for speed and efficiency.\n",
        "\n",
        "> Programmer:\n",
        "\n",
        "*   Initialize M base estimators (like decision trees) and weights for each variable ***Wi*** = 1/N.\n",
        "*   Train model using weights and adjust weights after each training step using cross_entropy loss function (which adds more weight to misclassified observations).\n",
        "*   [Code](https://github.com/KevinLolochum/Top-Ten-Machine-Learning-Cheatsheet/blob/main/XGBoost.py)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}
